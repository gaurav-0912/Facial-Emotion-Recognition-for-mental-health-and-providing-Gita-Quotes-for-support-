# -*- coding: utf-8 -*-
"""Updated_Emotion_Detection (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R_1DaL1S2t4CtvfQ87rRRMaGM5pFAxKY
"""

!wget https://www.dropbox.com/s/nilt43hyl1dx82k/dataset.zip?dl=0

!unzip dataset.zip?dl=0

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input
from tensorflow.keras.losses import categorical_crossentropy

"""#  Building our Model To train the data"""

# Working with pre trained model

base_model = MobileNet( input_shape=(224,224,3), include_top= False )

for layer in base_model.layers:
  layer.trainable = False


x = Flatten()(base_model.output)
x = Dense(units=7 , activation='softmax' )(x)

# creating our model.
model = Model(base_model.input, x)

model.compile(optimizer='adam', loss= categorical_crossentropy , metrics=['accuracy']  )

"""# Preparing our data using data generator"""

train_datagen = ImageDataGenerator(
     zoom_range = 0.2,
     shear_range = 0.2,
     horizontal_flip=True,
     rescale = 1./255
)

train_data = train_datagen.flow_from_directory(directory= "/content/train",
                                               target_size=(224,224),
                                               batch_size=32,
                                  )


train_data.class_indices

val_datagen = ImageDataGenerator(rescale = 1./255 )

val_data = val_datagen.flow_from_directory(directory= "/content/test",
                                           target_size=(224,224),
                                           batch_size=32,
                                  )

"""# visualizaing the data that is fed to train data gen"""

# Fetch a batch of images and their corresponding labels
t_img, label = next(train_data)  # Using Python's built-in iterator functionality

# Function to plot images from the training data generator
def plotImages(img_arr, label):
    """
    input  :- images array
    output :- plots the images
    """
    count = 0
    for im, l in zip(img_arr, label):
        plt.imshow(im)
        plt.title(f"Image Shape: {im.shape}")
        plt.axis('off')  # Correctly disables axis
        plt.show()

        count += 1
        if count == 10:  # Limit the number of images to show
            break

# Call the function to plot the images
plotImages(t_img, label)

"""# having early stopping and model check point"""

from keras.callbacks import ModelCheckpoint, EarlyStopping

# Early stopping
es = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=5, verbose=1, mode='auto')

# Model checkpoint
mc = ModelCheckpoint(filepath="best_model.keras", monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')

# Putting callback in a list
call_back = [es, mc]

hist = model.fit(
    train_data,  # Use train_data generator directly
    steps_per_epoch=10,
    epochs=30,
    validation_data=val_data,  # Use validation data generator directly
    validation_steps=8,
    callbacks=[es, mc]
)

import os
print(os.listdir('/content'))  # Lists files in /content directory

from keras.models import load_model

# Load the pre-trained model
model = load_model('/content/best_model.keras')

h =  hist.history
h.keys()

plt.plot(h['accuracy'])
plt.plot(h['val_accuracy'] , c = "red")
plt.title("acc vs v-acc")
plt.show()

plt.plot(h['loss'])
plt.plot(h['val_loss'] , c = "red")
plt.title("loss vs v-loss")
plt.show()

# just to map o/p values
op = dict(zip( train_data.class_indices.values(), train_data.class_indices.keys()))

# path for the image to see if it predics correct class

path = "/Passport_Photo.jpeg"
img = load_img(path, target_size=(224,224) )

i = img_to_array(img)/255
input_arr = np.array([i])
input_arr.shape

pred = np.argmax(model.predict(input_arr))

print(f" the image is of neutral")

# to display the image
plt.imshow(input_arr[0])
plt.title("input image")
plt.show()

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import seaborn as sns

# Define the correct image size based on your model's input shape
img_height = 224  # Update to match the input shape of your model
img_width = 224   # Update to match the input shape of your model
batch_size = 32   # Keep the batch size as per your needs

# Load the pre-trained model
model = load_model('best_model.keras')

# Load and preprocess test data with the correct image size
datagen = ImageDataGenerator(rescale=1./255)
test_generator = datagen.flow_from_directory(
    '/content/test',
    target_size=(img_height, img_width),  # Ensure that target_size matches the model's input size
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

# Get the test data and labels
X_test, y_test = test_generator.__next__()

# Make predictions
y_pred_prob = model.predict(X_test)
y_pred = np.argmax(y_pred_prob, axis=1)
y_true = np.argmax(y_test, axis=1)

# Now calculate metrics as before
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
f1 = f1_score(y_true, y_pred, average='weighted')

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Visualize confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()





